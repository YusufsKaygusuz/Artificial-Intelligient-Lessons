# ğŸš€ğŸ¤– Yapay Zeka Dersi ğŸ¦¾ğŸš€

<p align="center">
<img src="https://github.com/YusufsKaygusuz/Deneyap_Software_Techn/assets/86704802/a4e54abd-9ff4-4d8f-b784-bd0653e9b8f3" alt="ReLU" width="125"/>
<img src="https://github.com/YusufsKaygusuz/Deneyap_Software_Techn/assets/86704802/a90a23b8-0c21-40ee-9617-b17d2858b100" alt="ReLU" width="125"/>
<img src="https://github.com/YusufsKaygusuz/Artificial-Intelligient-Lessons/assets/86704802/cf3cd24d-6feb-47f0-9117-d9d305b6a7d7" alt="ReLU" width="150"/>
<img src="https://github.com/YusufsKaygusuz/Deneyap_Software_Techn/assets/86704802/705deb43-4977-46c8-8d32-b0c34b4b7b66" alt="ReLU" width="125"/>
<img src="https://github.com/YusufsKaygusuz/Deneyap_Software_Techn/assets/86704802/7bfa61ee-d340-41b9-8855-dec4c561744f" alt="ReLU" width="200"/> 
<img src="https://github.com/YusufsKaygusuz/Deneyap_Software_Techn/assets/86704802/cd98b111-b66c-4ddb-b0c4-f62ce0ab8b46" alt="ReLU" width="125"/>
</p>


## ğŸ“š Ä°Ã§indekiler
| Hafta | HaftalÄ±k Ä°Ã§erik                             |
|-------|--------------------------------------------|
| ğŸ“† Week 1 | [**Iris Veri Seti ile SÄ±nÄ±flandÄ±rma**](#week-1-iris-veri-seti-ile-sÄ±nÄ±flandÄ±rma) |
| ğŸ“† Week 2 | [**BulaÅŸÄ±k YÄ±kama SÃ¼resi Kontrol Sistemi**](#week-2-bulaÅŸÄ±k-yÄ±kama-sÃ¼resi-kontrol-sistemi) |
| ğŸ“† Week 3 | [**Naive Bayes ile Kalp Ritim Tespiti**](#week-3-naive-bayes-ile-kalp-ritim-tespiti) |
| ğŸ“† Week 4 | [**Kalp Ritim BozukluÄŸu Tespiti ve HastalÄ±klÄ± Yaprak Analizi**](#week-4-kalp-ritim-bozukluÄŸu-tespiti-ve-hastalÄ±klÄ±-yaprak-analizi) |
| ğŸ“† Week 5 | [**Yapay Sinir AÄŸlarÄ± ile IsÄ±tma ve SoÄŸutma YÃ¼kÃ¼ Tahmini**](#week-5-yapay-sinir-aÄŸlarÄ±-ile-isÄ±tma-ve-soÄŸutma-yÃ¼kÃ¼-tahmini) |


## Week 1: Iris Veri Seti ile SÄ±nÄ±flandÄ±rma

Bu proje, Python dilinde scikit-learn kÃ¼tÃ¼phanesini kullanarak Iris veri setini kullanarak K En YakÄ±n KomÅŸu (K Neighbors) ve Karar AÄŸacÄ± (Decision Tree) sÄ±nÄ±flandÄ±rma algoritmalarÄ±nÄ± nasÄ±l uygulayacaÄŸÄ±nÄ±zÄ± adÄ±m adÄ±m gÃ¶stermektedir.

<h3>â˜˜ï¸ Iris Veri Seti</h3>

Ä°ris veri seti, bitki bilimi alanÄ±nda yaygÄ±n olarak kullanÄ±lan bir veri setidir. ÃœÃ§ farklÄ± tÃ¼rde (setosa, versicolor, virginica) 150 adet iris Ã§iÃ§eÄŸi Ã¶rneÄŸini iÃ§erir. Her bir Ã¶rnek iÃ§in dÃ¶rt Ã¶zellik (uzunluk ve geniÅŸlik gibi) mevcuttur.

<h3>ğŸ¦¾ K En YakÄ±n KomÅŸu (K Neighbors) AlgoritmasÄ±</h3>

K En YakÄ±n KomÅŸu algoritmasÄ±, bir veri noktasÄ±nÄ± sÄ±nÄ±flandÄ±rmak iÃ§in komÅŸularÄ±nÄ±n etiketlerini kullanÄ±r. Bu proje, K En YakÄ±n KomÅŸu algoritmasÄ± kullanarak Iris veri setini sÄ±nÄ±flandÄ±rmayÄ± gÃ¶stermektedir.

<h3>ğŸ› ï¸ Kurulum</h3>

Bu projeyi Ã§alÄ±ÅŸtÄ±rmak iÃ§in Python ve scikit-learn kÃ¼tÃ¼phanesinin yÃ¼klÃ¼ olmasÄ± gerekir. Ä°lgili kÃ¼tÃ¼phaneleri yÃ¼klemek iÃ§in terminale ÅŸu komutu yazabilirsiniz:

```python
pip install scikit-learn seaborn pandas matplotlib
```

<h2>ğŸ” Kod Analizi </h2>
<h3>1. Veri Seti YÃ¼kleme</h3>
Ä°lk adÄ±mda, sklearn.datasets modÃ¼lÃ¼nden load_iris() fonksiyonunu kullanarak Iris veri setini yÃ¼klÃ¼yoruz.

```python
from sklearn.datasets import load_iris
iris = load_iris()
```

<h3>2. Veri Seti HakkÄ±nda Bilgiler</h3>
Daha sonra, yÃ¼klenen veri setinin Ã¶zellik adlarÄ±nÄ±, hedef sÄ±nÄ±f adlarÄ±nÄ±, hedef sÄ±nÄ±f dizisini ve veri noktalarÄ±nÄ± yazdÄ±rÄ±yoruz.

```python
print (iris.feature_names)
print (iris.target_names)
print (iris.target)
print (iris.data)
```

<h3>3. Veri Setini EÄŸitim ve Test Setlerine BÃ¶lme</h3>
Veri setini eÄŸitim ve test setlerine bÃ¶lmek iÃ§in train_test_split() fonksiyonunu kullanÄ±yoruz.

```python
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 0)
```

<h3>4. K En YakÄ±n KomÅŸu Modeli OluÅŸturma ve EÄŸitme</h3>
K En YakÄ±n KomÅŸu sÄ±nÄ±flandÄ±rma modelini oluÅŸturmak iÃ§in KNeighborsClassifier() sÄ±nÄ±fÄ±nÄ± kullanÄ±yoruz ve ardÄ±ndan eÄŸitim verilerini bu modele uyum saÄŸlÄ±yoruz.

```python
from sklearn.neighbors import KNeighborsClassifier
model =  KNeighborsClassifier()
model.fit(X_train,Y_train)
```

<h3>5. Model PerformansÄ±nÄ± DeÄŸerlendirme</h3>
EÄŸitilen modelin performansÄ±nÄ± deÄŸerlendirmek iÃ§in test seti Ã¼zerinde tahminler yaparak bir hata matrisi oluÅŸturuyoruz ve bu matrisi yazdÄ±rÄ±yoruz.

```python
Y_tahmin = model.predict(X_test)
from sklearn.metrics import confusion_matrix
hata_matrisi = confusion_matrix(Y_test, Y_tahmin)
print(hata_matrisi)
```

<h3>6. Hata Matrisini GÃ¶rselleÅŸtirme</h3>
Son olarak, oluÅŸturduÄŸumuz hata matrisini bir Ä±sÄ± haritasÄ± olarak gÃ¶rselleÅŸtiriyoruz.

```python
import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt
index = ['setosa','versicolor','virginica'] 
columns = ['setosa','versicolor','virginica'] 
hata_goster = pd.DataFrame(hata_matrisi,columns,index)                      
plt.figure(figsize=(10,6))  
sns.heatmap(hata_goster, annot=True)
```

---

## Week 2: BulaÅŸÄ±k YÄ±kama SÃ¼resi Kontrol Sistemi
Bu hafta, bulanÄ±klÄ±k mantÄ±ÄŸÄ± (fuzzy logic) kullanarak bulaÅŸÄ±k miktarÄ± ve kirlilik seviyesi gibi girdi deÄŸiÅŸkenlerine dayanarak bulaÅŸÄ±k yÄ±kama sÃ¼resini belirleyen bir kontrol sistemi oluÅŸturulur.

<h2>ğŸ” Kod Analizi</h2>
<h3>1. Ä°lgili kÃ¼tÃ¼phanelerin yÃ¼klenmesi</h3>

```python
import numpy as np
import skfuzzy as fuzz
from skfuzzy import control as ctrl
```

<h3>2. GiriÅŸ ve Ã§Ä±kÄ±ÅŸ deÄŸiÅŸkenlerinin tanÄ±mlanmasÄ±</h3>

```python
bulaÅŸÄ±k_miktarÄ± = ctrl.Antecedent(np.arange(0, 100, 1), 'bulaÅŸÄ±k miktarÄ±')
kirlilik = ctrl.Antecedent(np.arange(0, 100, 1), 'kirlilik seviyesi')
yÄ±kama_sÃ¼resi = ctrl.Consequent(np.arange(0, 180, 1), 'yÄ±kama sÃ¼resi')
```

<h3>3. Ãœyelik fonksiyonlarÄ±nÄ±n tanÄ±mlanmasÄ±</h3>

```python
bulaÅŸÄ±k_miktarÄ±['az'] = fuzz.trimf(bulaÅŸÄ±k_miktarÄ±.universe, [0, 0, 30])
bulaÅŸÄ±k_miktarÄ±['normal'] = fuzz.trimf(bulaÅŸÄ±k_miktarÄ±.universe, [10, 30, 60])
bulaÅŸÄ±k_miktarÄ±['Ã§ok'] = fuzz.trimf(bulaÅŸÄ±k_miktarÄ±.universe, [50, 60, 100])

kirlilik['az'] = fuzz.trimf(kirlilik.universe, [0, 0, 30])
kirlilik['normal'] = fuzz.trimf(kirlilik.universe, [10, 30, 60])
kirlilik['Ã§ok'] = fuzz.trimf(kirlilik.universe, [50, 60, 100])

yÄ±kama_sÃ¼resi['kÄ±sa'] = fuzz.trimf(yÄ±kama_sÃ¼resi.universe, [0, 0, 50])
yÄ±kama_sÃ¼resi['normal'] = fuzz.trimf(yÄ±kama_sÃ¼resi.universe, [40, 50, 100])
yÄ±kama_sÃ¼resi['uzun'] = fuzz.trimf(yÄ±kama_sÃ¼resi.universe, [60, 80, 180])
```

<h3>4. KurallarÄ±n TanÄ±mlanmasÄ±</h3>

```python
kural1 = ctrl.Rule(bulaÅŸÄ±k_miktarÄ±['az'] & kirlilik['az'], yÄ±kama_sÃ¼resi['kÄ±sa'])
kural2 = ctrl.Rule(bulaÅŸÄ±k_miktarÄ±['normal'] & kirlilik['az'], yÄ±kama_sÃ¼resi['normal'])
```

<h3>5. Kontrol sistemi ile simÃ¼lasyon oluÅŸturulmasÄ±</h3>
  
```python
kontrol_sistemi = ctrl.ControlSystem([kural1, kural2, ..., kural9])
model = ctrl.ControlSystemSimulation(kontrol_sistemi)
```

<h3>6. Girdi deÄŸerleri atanÄ±r ve Ã§Ä±ktÄ± hesaplanÄ±r</h3>
  
```python
model.input['bulaÅŸÄ±k miktarÄ±'] = 50
model.input['kirlilik seviyesi'] = 80
model.compute()
```

<h3>7. SonuÃ§ yazdÄ±rÄ±lÄ±r</h3>

```python
print(model.output['yÄ±kama sÃ¼resi'])
```

Bu betik, bulanÄ±klÄ±k mantÄ±ÄŸÄ± kullanarak bulaÅŸÄ±k yÄ±kama sÃ¼resini belirler. Bu sayede karmaÅŸÄ±k sistemlerdeki belirsizliÄŸi ve doÄŸrusal olmayan iliÅŸkileri modellemek iÃ§in kullanÄ±labilir.

---
## Week 3: Naive Bayes ile Kalp Ritim Tespiti

Bu proje, elektrokardiyogram (EKG) verilerini kullanarak Naive Bayes sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±nÄ± uygulamayÄ± amaÃ§lar. EKG sinyalleri, kalp ritminin analizinde kullanÄ±lan temel verilerdir.

<h3>AmaÃ§</h3>

EKG sinyallerini iÅŸleyerek, sinyaldeki farklÄ± aritmileri (kalp ritim bozukluklarÄ±) sÄ±nÄ±flandÄ±rmak.
Naive Bayes sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±nÄ± kullanarak aritmileri doÄŸru bir ÅŸekilde tanÄ±mlamak.

<h3>AdÄ±mlar</h3>

Veri YÃ¼kleme: EÄŸitim ve test veri setleri pandas kÃ¼tÃ¼phanesi kullanÄ±larak yÃ¼klenir.
Veri HazÄ±rlÄ±ÄŸÄ±: Veri setleri Ã¶zellikler ve etiketler olarak ayrÄ±lÄ±r.
Model EÄŸitimi: Naive Bayes sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ± kullanÄ±larak model eÄŸitilir.
Tahminler: Test veri seti Ã¼zerinde tahminler yapÄ±lÄ±r.
DeÄŸerlendirme: Modelin performansÄ±, karmaÅŸÄ±klÄ±k matrisi ve doÄŸruluk metriÄŸi kullanÄ±larak deÄŸerlendirilir.

<h3>KullanÄ±lan Kod ParÃ§alarÄ±</h3>

<h4>Veri setlerini yÃ¼kleme ve Ã¶zellikler ile etiketlerin ayrÄ±lmasÄ±:</h4>

```python
import numpy as np
import pandas as pd

train = pd.read_csv("mitbih_train.csv")
X_train = np.array(train)[:, :187] # Ã–zellikler
y_train = np.array(train)[:, 187]  #Â Etiketler

test = pd.read_csv("mitbih_test.csv")
X_test = np.array(test)[:, :187] # Ã–zellikler
y_test = np.array(test)[:, 187]  #Â Etiketler
```

<h4>Model eÄŸitimi ve tahminlerin yapÄ±lmasÄ±:</h4>

```python
from sklearn.naive_bayes import CategoricalNB

gnb = CategoricalNB()
gnb.fit(X_train, y_train)

y_pred = gnb.predict(X_test)
```


<h4>DeÄŸerlendirme ve sonuÃ§larÄ±n gÃ¶rselleÅŸtirilmesi:</h4>

```python
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, y_pred)

index = ['No' , 'S', 'V', 'F', 'Q']
columns = ['No' , 'S', 'V', 'F', 'Q']
cm_df = pd.DataFrame(cm, columns, index)

plt.figure(figsize=(10,6))
sns.heatmap(cm_df, annot=True, fmt="d", cmap="YlGnBu")
plt.show()

from sklearn import metrics
print("Accuracy: ", metrics.accuracy_score(y_test, y_pred))
```


<h4>KullanÄ±lan KÃ¼tÃ¼phaneler</h4>

<p>â™¾ï¸numpy: SayÄ±sal hesaplamalar iÃ§in kullanÄ±lÄ±r.</p>
<p>ğŸ“špandas: Veri manipÃ¼lasyonu ve analizi iÃ§in kullanÄ±lÄ±r.</p>
<p>ğŸ“–sklearn: Makine Ã¶ÄŸrenimi algoritmalarÄ±nÄ± ve metriklerini iÃ§erir.</p>
<p>ğŸ¨seaborn: Veri gÃ¶rselleÅŸtirmesi iÃ§in kullanÄ±lÄ±r.</p>
<p>ğŸ¨matplotlib: Grafik Ã§izimleri iÃ§in kullanÄ±lÄ±r.</p>

<h3>Naive Bayes SÄ±nÄ±flandÄ±rma Alg. <strong>%82,96</strong> DoÄŸruluk DeÄŸeri</h3>
<img src="https://github.com/YusufsKaygusuz/Artificial-Intelligient-Lessons/assets/86704802/9b900941-9be1-4e3c-a561-e7a84372e10c" alt="ReLU" width="550"/> 

<h3>Decision Tree SÄ±nÄ±flandÄ±rma Alg. <strong>%95,26</strong> DoÄŸruluk DeÄŸeri</h3>
<img src="https://github.com/YusufsKaygusuz/Artificial-Intelligient-Lessons/assets/86704802/4119e0ed-e4be-46c4-8429-528d309e4a17" alt="ReLU" width="550"/> 

<h3>Decision Tree SÄ±nÄ±flandÄ±rma Alg. (K-Cross = 10) <strong>%95,48</strong> DoÄŸruluk DeÄŸeri</h3>
<img src="https://github.com/YusufsKaygusuz/Artificial-Intelligient-Lessons/assets/86704802/62e6f831-72f9-4587-9094-10bc6fc50530" alt="ReLU" width="550"/> 

---

## Week 4: Kalp Ritim BozukluÄŸu Tespiti ve HastalÄ±klÄ± Yaprak Analizi

Bu kod, pirinÃ§ yaprak hastalÄ±klarÄ±nÄ± sÄ±nÄ±flandÄ±rmak iÃ§in bir makine Ã¶ÄŸrenimi modeli oluÅŸturur. AÅŸaÄŸÄ±da, kodun her bÃ¶lÃ¼mÃ¼nÃ¼ ayrÄ±ntÄ±lÄ± olarak aÃ§Ä±kladÄ±m.
<h3>1. KullanÄ±lan KÃ¼tÃ¼phaneneler</h3>

```python
import numpy as np
import pandas as pd
import os
import PIL.Image as img
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
```

- numpy: SayÄ±sal iÅŸlemler iÃ§in kullanÄ±lÄ±r.
- pandas: Veri analizi ve veri manipÃ¼lasyonu iÃ§in kullanÄ±lÄ±r.
- os: Dosya ve dizin iÅŸlemleri iÃ§in kullanÄ±lÄ±r.
- PIL.Image: GÃ¶rÃ¼ntÃ¼ iÅŸleme iÃ§in kullanÄ±lÄ±r.
- sklearn.model_selection: Veri setini eÄŸitim ve test kÃ¼melerine ayÄ±rmak iÃ§in kullanÄ±lÄ±r.
- sklearn.ensemble: RandomForestClassifier modelini oluÅŸturmak iÃ§in kullanÄ±lÄ±r.
- sklearn.metrics: Modelin doÄŸruluÄŸunu Ã¶lÃ§mek iÃ§in kullanÄ±lÄ±r.

<h3>2. Dosya ve Dizin Ä°ÅŸlemleri</h3>

```python
bakteri_yaprak_yanik = "rice_leaf_diseases/Bacterial leaf blight/"
kahve_nokta = "rice_leaf_diseases/Brown spot/"
yaprak_isi = "rice_leaf_diseases/Leaf smut"

def dosya(yol):
    return [os.path.join(yol, f) for f in os.listdir(yol)]
```

- bakteri_yaprak_yanik, kahve_nokta, yaprak_isi: FarklÄ± hastalÄ±k tÃ¼rlerine ait gÃ¶rÃ¼ntÃ¼lerin bulunduÄŸu dizinlerin yollarÄ±.
- dosya: Belirtilen yoldaki tÃ¼m dosyalarÄ±n tam yolunu dÃ¶ndÃ¼ren bir fonksiyon.


<h3>3. Veri DÃ¶nÃ¼ÅŸtÃ¼rme </h3>

```python
def veri_donusturme(klasor_adi, sinif_adi):
    goruntuler = dosya(klasor_adi)
    
    goruntu_sinif = []
    for goruntu in goruntuler:
        goruntu_oku = img.open(goruntu).convert('L')
        gorunu_boyutlandirma = goruntu_oku.resize((28, 28))
        goruntu_donusturme = np.array(gorunu_boyutlandirma).flatten()
        if sinif_adi == "bakteri_yaprak_yanik":
            veriler = np.append(goruntu_donusturme, [0])
        elif sinif_adi == "kahve_nokta":
            veriler = np.append(goruntu_donusturme, [1])
        elif sinif_adi == "yaprak_isi":
            veriler = np.append(goruntu_donusturme, [2])
        else:
            continue
        goruntu_sinif.append(veriler)

    return goruntu_sinif
```

- veri_donusturme: Belirtilen klasÃ¶rdeki gÃ¶rÃ¼ntÃ¼leri okuyup, 28x28 boyutuna getirerek dÃ¼zleÅŸtirir ve sÄ±nÄ±f etiketleriyle birlikte bir listeye ekler.

<h3>4. Verilerin Data Setlerinden YÃ¼klenmesi ve BirleÅŸtirilmesi </h3>

```python
yanik_veri = veri_donusturme(bakteri_yaprak_yanik, "bakteri_yaprak_yanik")
yanik_veri_df = pd.DataFrame(yanik_veri)

kahve_nokta_veri = veri_donusturme(kahve_nokta, "kahve_nokta")
kahve_nokta_veri_df = pd.DataFrame(kahve_nokta_veri)

yaprak_isi_veri = veri_donusturme(yaprak_isi, "yaprak_isi")
yaprak_isi_veri_df = pd.DataFrame(yaprak_isi_veri)

tum_veri = pd.concat([yanik_veri_df, kahve_nokta_veri_df, yaprak_isi_veri_df])
```

- Her bir hastalÄ±k sÄ±nÄ±fÄ± iÃ§in veri_donusturme fonksiyonu kullanÄ±larak veriler okunur ve bir DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.
- TÃ¼m veriler birleÅŸtirilir.


<h3>5. GiriÅŸ ve Ã‡Ä±kÄ±ÅŸ Verilerinin HazÄ±rlanmasÄ±</h3>

```python
Giris = np.array(tum_veri)[:,:784]
Cikis = np.array(tum_veri)[:,784]
```

- Giris: GÃ¶rÃ¼ntÃ¼ verilerini iÃ§erir.
- Cikis: SÄ±nÄ±f etiketlerini iÃ§erir.


<h3>6. Veri Setinin EÄŸitim(Train) ve test KÃ¼melerine AyrÄ±lmasÄ±</h3>

```python
Giris_train, Giris_test, Cikis_train, Cikis_test = train_test_split(Giris, Cikis, test_size=0.2, random_state=109)
```

- Veri seti %80 eÄŸitim ve %20 test olacak ÅŸekilde ayrÄ±lÄ±r.



<h3>7. Modelin EÄŸitilmesi ve Test Edilmesi</h3>

```python
model = RandomForestClassifier()
model.fit(Giris_train, Cikis_train)
```

- RandomForestClassifier modeli oluÅŸturulur ve eÄŸitim verileriyle eÄŸitilir.


<h3>8. Tahmin YapÄ±lmasÄ± ve DoÄŸruluk Ã–lÃ§Ã¼mÃ¼</h3>

```python
Cikis_pred = model.predict(Giris_test)
print("DoÄŸruluk:", metrics.accuracy_score(Cikis_test, Cikis_pred))
```

- Test verileri Ã¼zerinde tahmin yapÄ±lÄ±r ve modelin doÄŸruluÄŸu Ã¶lÃ§Ã¼lÃ¼r.


<h3>9. Ã–zetle Neyi Hedefledik? </h3>

<p>Kod, pirinÃ§ yaprak hastalÄ±klarÄ±nÄ± sÄ±nÄ±flandÄ±rmak iÃ§in bir makine Ã¶ÄŸrenimi modeli oluÅŸturur ve modelin doÄŸruluÄŸunu Ã¶lÃ§er. Bu model, gÃ¶rÃ¼ntÃ¼leri gri tonlamalÄ± yapÄ±p, yeniden boyutlandÄ±rarak ve dÃ¼zleÅŸtirerek Ã§alÄ±ÅŸÄ±r. RandomForestClassifier kullanÄ±larak hastalÄ±k sÄ±nÄ±flandÄ±rmasÄ± yapÄ±lÄ±r ve test verileri Ã¼zerinde doÄŸruluk Ã¶lÃ§Ã¼lÃ¼r. </p>



## Week 5: Yapay Sinir AÄŸlarÄ± ile IsÄ±tma ve SoÄŸutma YÃ¼kÃ¼ Tahmini

<p>Bu proje, Tsanas ve Xifara (2012) tarafÄ±ndan saÄŸlanan 768 Ã¶rnekten oluÅŸan bir veri setini kullanarak Ã§eÅŸitli giriÅŸ parametrelerine gÃ¶re binalarÄ±n Ä±sÄ±tma ve soÄŸutma yÃ¼klerini yapay sinir aÄŸlarÄ± (YSA) kullanarak tahmin etmeyi amaÃ§lamaktadÄ±r. </p>

<h2>Veri Seti</h2>
Veri seti aÅŸaÄŸÄ±daki giriÅŸ parametrelerini iÃ§ermektedir:

- ğŸ§±RÃ¶latif sÄ±kÄ±lÄ±k
- YÃ¼zey alanÄ±
- Duvar alanÄ±
- Ã‡atÄ± alanÄ±
- Bina yÃ¼ksekliÄŸi
- Oryantasyon
- Cam alanÄ±
- Cam alan daÄŸÄ±lÄ±mÄ±

<h3>Hedef Ã§Ä±ktÄ±lar ise</h3>

- IsÄ±tma yÃ¼kÃ¼
- SoÄŸutma yÃ¼kÃ¼

<h3>ğŸ—ï¸ Proje YapÄ±sÄ±</h3>
Proje aÅŸaÄŸÄ±daki adÄ±mlarÄ± iÃ§ermektedir:

- Verinin yÃ¼klenmesi ve Ã¶n iÅŸlenmesi
- Verinin eÄŸitim ve test setlerine ayrÄ±lmasÄ±
- Girdi Ã¶zelliklerinin Ã¶lÃ§eklendirilmesi
- YSA modelinin oluÅŸturulmasÄ±
- Modelin eÄŸitilmesi
- Modelin performansÄ±nÄ±n deÄŸerlendirilmesi


<h2>ğŸ› ï¸ Kurulum</h2>
Bu projeyi Ã§alÄ±ÅŸtÄ±rmak iÃ§in aÅŸaÄŸÄ±daki kÃ¼tÃ¼phanelerin yÃ¼klÃ¼ olmasÄ± gerekmektedir:

- numpy
- pandas
- scikit-learn
- keras
- tensorflow
- matplotlib

Bu kÃ¼tÃ¼phaneleri pip kullanarak yÃ¼kleyebilirsiniz:

```python
pip install numpy pandas scikit-learn keras tensorflow matplotlib
```

<h2>KullanÄ±m</h2>
<p>Veri seti bir Excel dosyasÄ±ndan yÃ¼klenir ve giriÅŸ Ã¶zellikleri (X) ve hedef Ã§Ä±ktÄ±lar (y) olarak ayrÄ±lÄ±r. Veri daha sonra eÄŸitim ve test setlerine bÃ¶lÃ¼nÃ¼r.</p>

<img src="https://github.com/YusufsKaygusuz/Artificial-Intelligient-Lessons/assets/86704802/8f5925cd-8ea8-4fd1-a61e-5e935117899a" alt="ReLU" width="550"/>




<h3>Verinin Ã–lÃ§eklendirilmesi</h3>
Girdi Ã¶zellikleri StandardScaler kullanÄ±larak Ã¶lÃ§eklendirilir, bÃ¶ylece verinin ortalamasÄ± 0 ve standart sapmasÄ± 1 olur. Bu, sinir aÄŸlarÄ±nÄ±n eÄŸitimi iÃ§in Ã¶nemlidir.

<h3>YSA Modelinin OluÅŸturulmasÄ±</h3>
IsÄ±tma ve soÄŸutma yÃ¼klerini tahmin etmek iÃ§in ortak bir yol ve iki ayrÄ± yol kullanan bir sinir aÄŸÄ± modeli Keras kullanÄ±larak oluÅŸturulur.

```python
# Girdi katmanÄ±nÄ± tanÄ±mla, veri kÃ¼mesindeki Ã¶zellik sayÄ±sÄ±na gÃ¶re ÅŸekil belirle
input_layer = Input(shape=(data_x_train_scaled.shape[1],), name='Input_Layer')

# Ä°lk yoÄŸun katmanÄ± tanÄ±mla, 128 birim ve 'relu' aktivasyon fonksiyonu kullan
common_path = Dense(units=128, activation='relu', name='First_Dense')(input_layer)

# AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi Ã¶nlemek iÃ§in dropout katmanÄ± ekle, dropout oranÄ± %30
common_path = Dropout(0.3)(common_path)

# Ä°kinci yoÄŸun katmanÄ± tanÄ±mla, yine 128 birim ve 'relu' aktivasyon fonksiyonu kullan
common_path = Dense(units=128, activation='relu', name='Second_Dense')(common_path)

# AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi Ã¶nlemek iÃ§in ikinci dropout katmanÄ± ekle, dropout oranÄ± %30
common_path = Dropout(0.3)(common_path)

# Ä°lk Ã§Ä±kÄ±ÅŸ katmanÄ±nÄ± tanÄ±mla, bir birim ile (IsÄ±tma yÃ¼kÃ¼ tahmini iÃ§in)
first_output = Dense(units=1, name='First_Output__Last_Layer')(common_path)

# Ä°kinci Ã§Ä±kÄ±ÅŸ yolu iÃ§in ilk yoÄŸun katmanÄ± tanÄ±mla, 64 birim ve 'relu' aktivasyon fonksiyonu kullan
second_output_path = Dense(units=64, activation='relu', name='Second_Output__First_Dense')(common_path)

# AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi Ã¶nlemek iÃ§in Ã¼Ã§Ã¼ncÃ¼ dropout katmanÄ± ekle, dropout oranÄ± %30
second_output_path = Dropout(0.3)(second_output_path)

# Ä°kinci Ã§Ä±kÄ±ÅŸ katmanÄ±nÄ± tanÄ±mla, bir birim ile (SoÄŸutma yÃ¼kÃ¼ tahmini iÃ§in)
second_output = Dense(units=1, name='Second_Output__Last_Layer')(second_output_path)

# Modeli tanÄ±mla, giriÅŸ katmanÄ± ve iki Ã§Ä±kÄ±ÅŸ katmanÄ±nÄ± belirt
model = Model(inputs=input_layer, outputs=[first_output, second_output])

```

<h3>Modelin EÄŸitilmesi</h3>
Model SGD optimizer ve ortalama kare hata (MSE) kaybÄ± ile derlenir. AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi Ã¶nlemek iÃ§in erken durdurma kullanÄ±lÄ±r.

```python
optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)
model.compile(optimizer=optimizer,
              loss={'First_Output__Last_Layer': 'mse', 'Second_Output__Last_Layer': 'mse'},
              metrics={'First_Output__Last_Layer': tf.keras.metrics.RootMeanSquaredError(),
                       'Second_Output__Last_Layer': tf.keras.metrics.RootMeanSquaredError()})

history = model.fit(x=data_x_train_scaled, y=data_y_train, verbose=0, epochs=500, batch_size=10,
                    validation_split=0.3, callbacks=[EarlyStopping(monitor='val_loss', patience=10)])
```


<h3>Modelin DeÄŸerlendirilmesi</h3>
Modelin performansÄ± test seti Ã¼zerinde R-kare metriÄŸi kullanÄ±larak deÄŸerlendirilir.

```python
y_pred = np.array(model.predict(data_x_test_scaled))
print("Ä°lk Ã§Ä±kÄ±ÅŸÄ±n R2 deÄŸeri:", r2_score(data_y_test[:, 0], y_pred[0, :].flatten()))
print("Ä°kinci Ã§Ä±kÄ±ÅŸÄ±n R2 deÄŸeri:", r2_score(data_y_test[:, 1], y_pred[1, :].flatten()))
```


<h3>SonuÃ§larÄ±n GÃ¶sterilmesi</h3>
EÄŸitim ve doÄŸrulama setleri iÃ§in RMSE kayÄ±plarÄ±nÄ±n grafiÄŸi Ã§izilerek modelin performansÄ± gÃ¶rselleÅŸtirilir.

```python
import matplotlib.pyplot as plt
plt.plot(history.history['First_Output__Last_Layer_root_mean_squared_error'])
plt.plot(history.history['val_First_Output__Last_Layer_root_mean_squared_error'])
plt.title("Ä°lk Ã‡Ä±kÄ±ÅŸ iÃ§in RMSE DeÄŸerleri")
plt.ylabel('RMSE')
plt.xlabel('Epoch')
plt.legend(['EÄŸitim', 'DoÄŸrulama'], loc='upper right')
plt.show()

plt.plot(history.history['Second_Output__Last_Layer_root_mean_squared_error'])
plt.plot(history.history['val_Second_Output__Last_Layer_root_mean_squared_error'])
plt.title("Ä°kinci Ã‡Ä±kÄ±ÅŸ iÃ§in RMSE DeÄŸerleri")
plt.ylabel('RMSE')
plt.xlabel('Epoch')
plt.legend(['EÄŸitim', 'DoÄŸrulama'], loc='upper right')
plt.show()
```

<h2>ğŸ“ SonuÃ§</h2>
Bu proje, Ã§eÅŸitli parametrelere dayalÄ± olarak binalarÄ±n Ä±sÄ±tma ve soÄŸutma yÃ¼klerini tahmin etmek iÃ§in yapay sinir aÄŸlarÄ±nÄ±n nasÄ±l kullanÄ±lacaÄŸÄ±nÄ± gÃ¶stermektedir. SonuÃ§lar, bÃ¶yle bir regresyon gÃ¶revi iÃ§in Ã§ok Ã§Ä±kÄ±ÅŸlÄ± bir model kullanmanÄ±n etkinliÄŸini gÃ¶stermektedir.
