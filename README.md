# ğŸš€ğŸ¤– Yapay Zeka Dersi ğŸ¦¾ğŸš€

<p align="center">
<img src="https://github.com/YusufsKaygusuz/Deneyap_Software_Techn/assets/86704802/cd98b111-b66c-4ddb-b0c4-f62ce0ab8b46" alt="ReLU" width="150"/>
<img src="https://github.com/YusufsKaygusuz/Deneyap_Software_Techn/assets/86704802/7bfa61ee-d340-41b9-8855-dec4c561744f" alt="ReLU" width="200"/> 
<img src="https://github.com/YusufsKaygusuz/Deneyap_Software_Techn/assets/86704802/a4e54abd-9ff4-4d8f-b784-bd0653e9b8f3" alt="ReLU" width="150"/>
<img src="https://github.com/YusufsKaygusuz/Deneyap_Software_Techn/assets/86704802/a90a23b8-0c21-40ee-9617-b17d2858b100" alt="ReLU" width="150"/>
<img src="https://github.com/YusufsKaygusuz/Deneyap_Software_Techn/assets/86704802/705deb43-4977-46c8-8d32-b0c34b4b7b66" alt="ReLU" width="150"/>

</p>


## ğŸ“š Ä°Ã§indekiler
| Hafta | HaftalÄ±k Ä°Ã§erik                             |
|-------|--------------------------------------------|
| ğŸ“† Week 1 | [**Iris Veri Seti ile SÄ±nÄ±flandÄ±rma**](#week-1-iris-veri-seti-ile-sÄ±nÄ±flandÄ±rma) |
| ğŸ“† Week 2 | [**BulaÅŸÄ±k YÄ±kama SÃ¼resi Kontrol Sistemi**](#week-2-bulaÅŸÄ±k-yÄ±kama-sÃ¼resi-kontrol-sistemi) |
| ğŸ“† Week 3 | [**Naive Bayes ile Kalp Ritim Tespiti**](#week-3-naive-bayes-ile-kalp-ritim-tespiti) |

## Week 1: Iris Veri Seti ile SÄ±nÄ±flandÄ±rma

Bu proje, Python dilinde scikit-learn kÃ¼tÃ¼phanesini kullanarak Iris veri setini kullanarak K En YakÄ±n KomÅŸu (K Neighbors) ve Karar AÄŸacÄ± (Decision Tree) sÄ±nÄ±flandÄ±rma algoritmalarÄ±nÄ± nasÄ±l uygulayacaÄŸÄ±nÄ±zÄ± adÄ±m adÄ±m gÃ¶stermektedir.

<h3>â˜˜ï¸ Iris Veri Seti</h3>

Ä°ris veri seti, bitki bilimi alanÄ±nda yaygÄ±n olarak kullanÄ±lan bir veri setidir. ÃœÃ§ farklÄ± tÃ¼rde (setosa, versicolor, virginica) 150 adet iris Ã§iÃ§eÄŸi Ã¶rneÄŸini iÃ§erir. Her bir Ã¶rnek iÃ§in dÃ¶rt Ã¶zellik (uzunluk ve geniÅŸlik gibi) mevcuttur.

<h3>ğŸ¦¾ K En YakÄ±n KomÅŸu (K Neighbors) AlgoritmasÄ±</h3>

K En YakÄ±n KomÅŸu algoritmasÄ±, bir veri noktasÄ±nÄ± sÄ±nÄ±flandÄ±rmak iÃ§in komÅŸularÄ±nÄ±n etiketlerini kullanÄ±r. Bu proje, K En YakÄ±n KomÅŸu algoritmasÄ± kullanarak Iris veri setini sÄ±nÄ±flandÄ±rmayÄ± gÃ¶stermektedir.

<h3>ğŸ› ï¸ Kurulum</h3>

Bu projeyi Ã§alÄ±ÅŸtÄ±rmak iÃ§in Python ve scikit-learn kÃ¼tÃ¼phanesinin yÃ¼klÃ¼ olmasÄ± gerekir. Ä°lgili kÃ¼tÃ¼phaneleri yÃ¼klemek iÃ§in terminale ÅŸu komutu yazabilirsiniz:

```python
pip install scikit-learn seaborn pandas matplotlib
```

<h2>ğŸ” Kod Analizi </h2>
<h3>1. Veri Seti YÃ¼kleme</h3>
Ä°lk adÄ±mda, sklearn.datasets modÃ¼lÃ¼nden load_iris() fonksiyonunu kullanarak Iris veri setini yÃ¼klÃ¼yoruz.

```python
from sklearn.datasets import load_iris
iris = load_iris()
```

<h3>2. Veri Seti HakkÄ±nda Bilgiler</h3>
Daha sonra, yÃ¼klenen veri setinin Ã¶zellik adlarÄ±nÄ±, hedef sÄ±nÄ±f adlarÄ±nÄ±, hedef sÄ±nÄ±f dizisini ve veri noktalarÄ±nÄ± yazdÄ±rÄ±yoruz.

```python
print (iris.feature_names)
print (iris.target_names)
print (iris.target)
print (iris.data)
```

<h3>3. Veri Setini EÄŸitim ve Test Setlerine BÃ¶lme</h3>
Veri setini eÄŸitim ve test setlerine bÃ¶lmek iÃ§in train_test_split() fonksiyonunu kullanÄ±yoruz.

```python
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 0)
```

<h3>4. K En YakÄ±n KomÅŸu Modeli OluÅŸturma ve EÄŸitme</h3>
K En YakÄ±n KomÅŸu sÄ±nÄ±flandÄ±rma modelini oluÅŸturmak iÃ§in KNeighborsClassifier() sÄ±nÄ±fÄ±nÄ± kullanÄ±yoruz ve ardÄ±ndan eÄŸitim verilerini bu modele uyum saÄŸlÄ±yoruz.

```python
from sklearn.neighbors import KNeighborsClassifier
model =  KNeighborsClassifier()
model.fit(X_train,Y_train)
```

<h3>5. Model PerformansÄ±nÄ± DeÄŸerlendirme</h3>
EÄŸitilen modelin performansÄ±nÄ± deÄŸerlendirmek iÃ§in test seti Ã¼zerinde tahminler yaparak bir hata matrisi oluÅŸturuyoruz ve bu matrisi yazdÄ±rÄ±yoruz.

```python
Y_tahmin = model.predict(X_test)
from sklearn.metrics import confusion_matrix
hata_matrisi = confusion_matrix(Y_test, Y_tahmin)
print(hata_matrisi)
```

<h3>6. Hata Matrisini GÃ¶rselleÅŸtirme</h3>
Son olarak, oluÅŸturduÄŸumuz hata matrisini bir Ä±sÄ± haritasÄ± olarak gÃ¶rselleÅŸtiriyoruz.

```python
import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt
index = ['setosa','versicolor','virginica'] 
columns = ['setosa','versicolor','virginica'] 
hata_goster = pd.DataFrame(hata_matrisi,columns,index)                      
plt.figure(figsize=(10,6))  
sns.heatmap(hata_goster, annot=True)
```


## Week 2: BulaÅŸÄ±k YÄ±kama SÃ¼resi Kontrol Sistemi
Bu hafta, bulanÄ±klÄ±k mantÄ±ÄŸÄ± (fuzzy logic) kullanarak bulaÅŸÄ±k miktarÄ± ve kirlilik seviyesi gibi girdi deÄŸiÅŸkenlerine dayanarak bulaÅŸÄ±k yÄ±kama sÃ¼resini belirleyen bir kontrol sistemi oluÅŸturulur.

<h2>ğŸ” Kod Analizi</h2>
<h3>1. Ä°lgili kÃ¼tÃ¼phanelerin yÃ¼klenmesi</h3>

```python
import numpy as np
import skfuzzy as fuzz
from skfuzzy import control as ctrl
```

<h3>2. GiriÅŸ ve Ã§Ä±kÄ±ÅŸ deÄŸiÅŸkenlerinin tanÄ±mlanmasÄ±</h3>

```python
bulaÅŸÄ±k_miktarÄ± = ctrl.Antecedent(np.arange(0, 100, 1), 'bulaÅŸÄ±k miktarÄ±')
kirlilik = ctrl.Antecedent(np.arange(0, 100, 1), 'kirlilik seviyesi')
yÄ±kama_sÃ¼resi = ctrl.Consequent(np.arange(0, 180, 1), 'yÄ±kama sÃ¼resi')
```

<h3>3. Ãœyelik fonksiyonlarÄ±nÄ±n tanÄ±mlanmasÄ±</h3>

```python
bulaÅŸÄ±k_miktarÄ±['az'] = fuzz.trimf(bulaÅŸÄ±k_miktarÄ±.universe, [0, 0, 30])
bulaÅŸÄ±k_miktarÄ±['normal'] = fuzz.trimf(bulaÅŸÄ±k_miktarÄ±.universe, [10, 30, 60])
bulaÅŸÄ±k_miktarÄ±['Ã§ok'] = fuzz.trimf(bulaÅŸÄ±k_miktarÄ±.universe, [50, 60, 100])

kirlilik['az'] = fuzz.trimf(kirlilik.universe, [0, 0, 30])
kirlilik['normal'] = fuzz.trimf(kirlilik.universe, [10, 30, 60])
kirlilik['Ã§ok'] = fuzz.trimf(kirlilik.universe, [50, 60, 100])

yÄ±kama_sÃ¼resi['kÄ±sa'] = fuzz.trimf(yÄ±kama_sÃ¼resi.universe, [0, 0, 50])
yÄ±kama_sÃ¼resi['normal'] = fuzz.trimf(yÄ±kama_sÃ¼resi.universe, [40, 50, 100])
yÄ±kama_sÃ¼resi['uzun'] = fuzz.trimf(yÄ±kama_sÃ¼resi.universe, [60, 80, 180])
```

<h3>4. KurallarÄ±n TanÄ±mlanmasÄ±</h3>

```python
kural1 = ctrl.Rule(bulaÅŸÄ±k_miktarÄ±['az'] & kirlilik['az'], yÄ±kama_sÃ¼resi['kÄ±sa'])
kural2 = ctrl.Rule(bulaÅŸÄ±k_miktarÄ±['normal'] & kirlilik['az'], yÄ±kama_sÃ¼resi['normal'])
```

<h3>5. Kontrol sistemi ile simÃ¼lasyon oluÅŸturulmasÄ±</h3>
  
```python
kontrol_sistemi = ctrl.ControlSystem([kural1, kural2, ..., kural9])
model = ctrl.ControlSystemSimulation(kontrol_sistemi)
```

<h3>6. Girdi deÄŸerleri atanÄ±r ve Ã§Ä±ktÄ± hesaplanÄ±r</h3>
  
```python
model.input['bulaÅŸÄ±k miktarÄ±'] = 50
model.input['kirlilik seviyesi'] = 80
model.compute()
```

<h3>7. SonuÃ§ yazdÄ±rÄ±lÄ±r</h3>

```python
print(model.output['yÄ±kama sÃ¼resi'])
```

Bu betik, bulanÄ±klÄ±k mantÄ±ÄŸÄ± kullanarak bulaÅŸÄ±k yÄ±kama sÃ¼resini belirler. Bu sayede karmaÅŸÄ±k sistemlerdeki belirsizliÄŸi ve doÄŸrusal olmayan iliÅŸkileri modellemek iÃ§in kullanÄ±labilir.




## Week 3: Naive Bayes ile Kalp Ritim Tespiti

Bu proje, elektrokardiyogram (EKG) verilerini kullanarak Naive Bayes sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±nÄ± uygulamayÄ± amaÃ§lar. EKG sinyalleri, kalp ritminin analizinde kullanÄ±lan temel verilerdir.

<h3>AmaÃ§</h3>

EKG sinyallerini iÅŸleyerek, sinyaldeki farklÄ± aritmileri (kalp ritim bozukluklarÄ±) sÄ±nÄ±flandÄ±rmak.
Naive Bayes sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±nÄ± kullanarak aritmileri doÄŸru bir ÅŸekilde tanÄ±mlamak.

<h3>AdÄ±mlar</h3>

Veri YÃ¼kleme: EÄŸitim ve test veri setleri pandas kÃ¼tÃ¼phanesi kullanÄ±larak yÃ¼klenir.
Veri HazÄ±rlÄ±ÄŸÄ±: Veri setleri Ã¶zellikler ve etiketler olarak ayrÄ±lÄ±r.
Model EÄŸitimi: Naive Bayes sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ± kullanÄ±larak model eÄŸitilir.
Tahminler: Test veri seti Ã¼zerinde tahminler yapÄ±lÄ±r.
DeÄŸerlendirme: Modelin performansÄ±, karmaÅŸÄ±klÄ±k matrisi ve doÄŸruluk metriÄŸi kullanÄ±larak deÄŸerlendirilir.

<h3>KullanÄ±lan Kod ParÃ§alarÄ±</h3>

<h4>Veri setlerini yÃ¼kleme ve Ã¶zellikler ile etiketlerin ayrÄ±lmasÄ±:</h4>

```python
import numpy as np
import pandas as pd

train = pd.read_csv("mitbih_train.csv")
X_train = np.array(train)[:, :187] # Ã–zellikler
y_train = np.array(train)[:, 187]  #Â Etiketler

test = pd.read_csv("mitbih_test.csv")
X_test = np.array(test)[:, :187] # Ã–zellikler
y_test = np.array(test)[:, 187]  #Â Etiketler
```

<h4>Model eÄŸitimi ve tahminlerin yapÄ±lmasÄ±:</h4>

```python
from sklearn.naive_bayes import CategoricalNB

gnb = CategoricalNB()
gnb.fit(X_train, y_train)

y_pred = gnb.predict(X_test)
```


<h4>DeÄŸerlendirme ve sonuÃ§larÄ±n gÃ¶rselleÅŸtirilmesi:</h4>

```python
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, y_pred)

index = ['No' , 'S', 'V', 'F', 'Q']
columns = ['No' , 'S', 'V', 'F', 'Q']
cm_df = pd.DataFrame(cm, columns, index)

plt.figure(figsize=(10,6))
sns.heatmap(cm_df, annot=True, fmt="d", cmap="YlGnBu")
plt.show()

from sklearn import metrics
print("Accuracy: ", metrics.accuracy_score(y_test, y_pred))
```


<h4>KullanÄ±lan KÃ¼tÃ¼phaneler</h4>

<p>â™¾ï¸numpy: SayÄ±sal hesaplamalar iÃ§in kullanÄ±lÄ±r.</p>
<p>ğŸ“špandas: Veri manipÃ¼lasyonu ve analizi iÃ§in kullanÄ±lÄ±r.</p>
<p>ğŸ“–sklearn: Makine Ã¶ÄŸrenimi algoritmalarÄ±nÄ± ve metriklerini iÃ§erir.</p>
<p>ğŸ¨seaborn: Veri gÃ¶rselleÅŸtirmesi iÃ§in kullanÄ±lÄ±r.</p>
<p>ğŸ¨matplotlib: Grafik Ã§izimleri iÃ§in kullanÄ±lÄ±r.</p>
